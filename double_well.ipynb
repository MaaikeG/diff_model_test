{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from diffusionmodel import *\n",
    "from torch.optim import Adam\n",
    "import bgflow.distribution.sampling.mcmc as MCMC\n",
    "import bgflow.distribution.energy.double_well as DoubleWell\n",
    "import bgflow.distribution.normal as Normal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "torch.random.manual_seed(199)\n",
    "\n",
    "device = 'cuda'\n",
    "T = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = DoubleWell.DoubleWellEnergy(dim=1, b=-4., c=1.)\n",
    "prior = Normal.NormalDistribution(dim=1)\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 64), \n",
    "    torch.nn.SiLU(), \n",
    "    torch.nn.Linear(64, 128),  \n",
    "    torch.nn.SiLU(), \n",
    "    torch.nn.Linear(128, 64),  \n",
    "    torch.nn.SiLU(), \n",
    "    torch.nn.Linear(64, 1))\n",
    "\n",
    "\n",
    "ts = torch.linspace(0, T, 50)\n",
    "xs = torch.linspace(-3, 3, 50)\n",
    "\n",
    "X, Y = torch.meshgrid(xs, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = MCMC.GaussianMCMCSampler(energy=target, init_state=torch.tensor([0.]))\n",
    "\n",
    "from utils import load_or_generate_and_then_save\n",
    "datafilepath = 'double_well.npy'\n",
    "data = torch.from_numpy(load_or_generate_and_then_save(datafilepath, lambda : sampler.sample(n_samples=50000)))\n",
    "\n",
    "# plot histogram of the sampled data\n",
    "counts, bins = np.histogram(data, bins=xs, density=True)\n",
    "# plt.plot(bins, torch.exp(-target.energy(torch.tensor(bins).unsqueeze_(1))))\n",
    "plt.stairs(counts, bins, fill=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_schedule = torch.linspace(1e-4, 0.05, T)\n",
    "diff_model = DiffusionModel(net=net, variance_schedule=beta_schedule, device=device)\n",
    "print(sum([len(p) for p in diff_model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.zeros_like(X)\n",
    "for i, t in enumerate(range(0, T, 2)):\n",
    "    t_s=torch.full(data.shape, t).to(device)\n",
    "    x_t = diff_model.apply_noise(x_0=data.to(device), t_s=t_s)[0]\n",
    "    z[:, i] = torch.histogram(x_t.cpu(), bins=torch.cat([xs.cpu(), torch.tensor([6.])]), density=True)[0]\n",
    "\n",
    "\n",
    "im1=plt.contourf(X.cpu(), Y.cpu(), z.cpu(), keepdim=True, levels=np.linspace(0, 0.5,50))\n",
    "plt.colorbar(im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
    "optimizer = Adam(diff_model.parameters(), lr=1e-3)\n",
    "scheduler =torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, cooldown=3, verbose=True)\n",
    "\n",
    "from train import train\n",
    "def callback(model):\n",
    "      samples = diff_model.sample([1000, 1])\n",
    "\n",
    "      # plot histogram of the sampled data\n",
    "      counts, bins = np.histogram(samples.cpu(), bins=xs, density=True)\n",
    "      # plt.plot(bins, torch.exp(-target.energy(torch.tensor(bins).unsqueeze_(1))))\n",
    "      plt.stairs(counts, bins, fill=True)\n",
    "      plt.show()\n",
    "\n",
    "\n",
    "train(diff_model, \n",
    "      loss_fn=torch.nn.MSELoss(), \n",
    "      optimizer=optimizer, \n",
    "      data_loader=train_loader, \n",
    "      scheduler=scheduler, \n",
    "      n_iterations=50, \n",
    "      device=device, \n",
    "      callback_interval=5,\n",
    "      callback=callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = diff_model.sample([10000, 1])\n",
    "\n",
    "# plot histogram of the sampled data\n",
    "counts, bins = np.histogram(samples.cpu(), bins=xs, density=True)\n",
    "# plt.plot(bins, torch.exp(-target.energy(torch.tensor(bins).unsqueeze_(1))))\n",
    "plt.stairs(counts, bins, fill=True, alpha=0.5, label=\"Model samples\")\n",
    "\n",
    "# plot histogram of the sampled data\n",
    "counts, bins = np.histogram(data, bins=xs, density=True)\n",
    "# plt.plot(bins, torch.exp(-target.energy(torch.tensor(bins).unsqueeze_(1))))\n",
    "plt.stairs(counts, bins, fill=True, alpha=0.5, label=\"data samples\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nequip')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0c35abcaeddf7152a696cea6320d65b93ade89382813fb9cb5d0aa9107b47ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
